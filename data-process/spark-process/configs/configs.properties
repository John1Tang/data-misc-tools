hive.exec.compress.intermediate=true
hive.merge.mapredfiles=false
hive.merge.smallfiles.avgsize=16000000
hive.merge.size.per.task=256000000
hive.merge.sparkfiles=true
hive.auto.convert.join=true
hive.auto.convert.join.noconditionaltask=true
hive.auto.convert.join.noconditionaltask.size=894435328
hive.optimize.bucketmapjoin.sortedmerge=false
hive.map.aggr.hash.percentmemory=0.5
hive.map.aggr=true
hive.optimize.sort.dynamic.partition=false
hive.stats.autogather=true
hive.stats.fetch.column.stats=true
hive.compute.query.using.stats=true
hive.limit.pushdown.memory.usage=0.4
hive.optimize.index.filter=true
hive.exec.reducers.bytes.per.reducer=67108864
hive.smbjoin.cache.rows=10000
hive.fetch.task.conversion=more
hive.fetch.task.conversion.threshold=1073741824
hive.optimize.ppd=true
mapreduce.input.fileinputformat.split.maxsize=750000000
hive.vectorized.execution.enabled=true
hive.cbo.enable=true
hive.optimize.reducededuplication.min.reducer=4
hive.optimize.reducededuplication=true
hive.orc.splits.include.file.footer=false
hive.merge.mapfiles=true
hive.merge.orcfile.stripe.level=true
hive.vectorized.execution.reduce.enabled=false
hive.vectorized.groupby.checkinterval=4096
hive.vectorized.groupby.flush.percent=0.1
hive.exec.orc.default.stripe.size=67108864
hive.fetch.task.aggr=false
mapreduce.input.fileinputformat.list-status.num-threads=5
hive.metastore.uris=thrift://some-server:9083

spark.app.name=spark-data-processor

record.jdbc.url=jdbc:mysql://fat.thenetcircle.lab:3306/spark_proc?user=dm&password=dm&autoReconnect=true&createDatabaseIfNotExist=true&useSSL=false
#record.jdbc.username=dm
#record.jdbc.password=dm
record.jdbc.username=hive
record.jdbc.password=hive

zk.servers="10.20.2.103:12181,10.20.2.102:12181,10.20.2.101:12181"

bootstrap.servers=10.20.2.103:9092,10.20.2.102:9092,10.20.2.101:9092
stream.interval=120
stream.checkpoint=/tmp/checkpoints/kafka
auto.offset.reset=earliest
group.id=importer
max.poll.records=1000
zookeeper.connection.timeout.ms=10000

hive.aux.jars.folder=file:///usr/local/tncdata/apps/apache-hive-2.3.0-bin/udf/
jdbc.hive.url=jdbc:hive2://cloud-host-01:10001/
entrance.script=/user/tncdata/scripts/spark/ProcessorLoader.scala